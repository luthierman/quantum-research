{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "blackjack_quantum.ipynb",
      "provenance": [],
      "mount_file_id": "1RYowm75qkQRjMAyvn0Rp9fc71ooEnjcF",
      "authorship_tag": "ABX9TyNFosaS4Ys+DlJzNIavMbJe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luthierman/quantum-research/blob/main/blackjack_quantum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NC4fNUOGYSEy",
        "outputId": "1f48d1f8-6e9a-48f0-dae7-b5e2deee3170"
      },
      "source": [
        "!pip install tensorflow==2.3.1\n",
        "!pip install tensorflow-quantum\n",
        "!pip install gym"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/18/374af421dfbe74379a458e58ab40cf46b35c3206ce8e183e28c1c627494d/tensorflow-2.3.1-cp37-cp37m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 48kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (0.36.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (1.12.1)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (2.4.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (1.32.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (0.12.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (2.10.0)\n",
            "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/ed/5853ec0ae380cba4588eab1524e18ece1583b65f7ae0e97321f5ff9dfd60/tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 39.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (3.12.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (0.2.0)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/c6/58e517e8b1fb192725cfa23c01c2e60e4e6699314ee9684a1c5f5c9b27e1/numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (1.1.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (1.28.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (0.4.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (56.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (3.10.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (3.1.0)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, numpy, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed numpy-1.18.5 tensorflow-2.3.1 tensorflow-estimator-2.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-quantum\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/02/878b2d4e7711f5c7f8dff9ff838e8ed84d218a359154ce06c7c01178a125/tensorflow_quantum-0.4.0-cp37-cp37m-manylinux2010_x86_64.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 4.1MB/s \n",
            "\u001b[?25hCollecting cirq==0.9.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/05/39c24828744b91f658fd1e5d105a9d168da43698cfaec006179c7646c71c/cirq-0.9.1-py3-none-any.whl (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 43.8MB/s \n",
            "\u001b[?25hCollecting sympy==1.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/a7/25d5d6b3295537ab90bdbcd21e464633fb4a0684dd9a065da404487625bb/sympy-1.5-py2.py3-none-any.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 50.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.16 in /usr/local/lib/python3.7/dist-packages (from cirq==0.9.1->tensorflow-quantum) (1.18.5)\n",
            "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from cirq==0.9.1->tensorflow-quantum) (1.26.3)\n",
            "Requirement already satisfied: requests~=2.18 in /usr/local/lib/python3.7/dist-packages (from cirq==0.9.1->tensorflow-quantum) (2.23.0)\n",
            "Requirement already satisfied: protobuf~=3.12.0 in /usr/local/lib/python3.7/dist-packages (from cirq==0.9.1->tensorflow-quantum) (3.12.4)\n",
            "Collecting freezegun~=0.3.15\n",
            "  Downloading https://files.pythonhosted.org/packages/17/5d/1b9d6d3c7995fff473f35861d674e0113a5f0bd5a72fe0199c3f254665c7/freezegun-0.3.15-py2.py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.7/dist-packages (from cirq==0.9.1->tensorflow-quantum) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cirq==0.9.1->tensorflow-quantum) (1.4.1)\n",
            "Requirement already satisfied: sortedcontainers~=2.0 in /usr/local/lib/python3.7/dist-packages (from cirq==0.9.1->tensorflow-quantum) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cirq==0.9.1->tensorflow-quantum) (3.7.4.3)\n",
            "Requirement already satisfied: networkx~=2.4 in /usr/local/lib/python3.7/dist-packages (from cirq==0.9.1->tensorflow-quantum) (2.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from cirq==0.9.1->tensorflow-quantum) (1.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy==1.5->tensorflow-quantum) (1.2.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq==0.9.1->tensorflow-quantum) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq==0.9.1->tensorflow-quantum) (1.53.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq==0.9.1->tensorflow-quantum) (1.15.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq==0.9.1->tensorflow-quantum) (20.9)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq==0.9.1->tensorflow-quantum) (56.0.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq==0.9.1->tensorflow-quantum) (1.28.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.29.0; extra == \"grpc\" in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq==0.9.1->tensorflow-quantum) (1.32.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests~=2.18->cirq==0.9.1->tensorflow-quantum) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests~=2.18->cirq==0.9.1->tensorflow-quantum) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.18->cirq==0.9.1->tensorflow-quantum) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.18->cirq==0.9.1->tensorflow-quantum) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil!=2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from freezegun~=0.3.15->cirq==0.9.1->tensorflow-quantum) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->cirq==0.9.1->tensorflow-quantum) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->cirq==0.9.1->tensorflow-quantum) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->cirq==0.9.1->tensorflow-quantum) (1.3.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx~=2.4->cirq==0.9.1->tensorflow-quantum) (4.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq==0.9.1->tensorflow-quantum) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq==0.9.1->tensorflow-quantum) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq==0.9.1->tensorflow-quantum) (4.2.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq==0.9.1->tensorflow-quantum) (0.4.8)\n",
            "Installing collected packages: freezegun, sympy, cirq, tensorflow-quantum\n",
            "  Found existing installation: sympy 1.7.1\n",
            "    Uninstalling sympy-1.7.1:\n",
            "      Successfully uninstalled sympy-1.7.1\n",
            "Successfully installed cirq-0.9.1 freezegun-0.3.15 sympy-1.5 tensorflow-quantum-0.4.0\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29Th6DRAYgGw"
      },
      "source": [
        "import os.path\n",
        "from os import path\n",
        "def make_path(p, d):\n",
        "  print(\"Checking if {} exists...\".format(p+d))\n",
        "  if path.exists(p+d) == False:\n",
        "    print(\"making... new directory\")\n",
        "    os.mkdir(p+str(d))\n",
        "  print(\"finished!\")\n",
        "  print(p+str(d))\n",
        "  return p+str(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUEOYd2WYgk7",
        "outputId": "96721462-d8a8-4611-ddb7-0e9d1960410b"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from collections import deque\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "import time\n",
        "import tensorflow_quantum as tfq\n",
        "import cirq \n",
        "import sympy\n",
        "import gym\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from collections import deque\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "import time\n",
        "import tensorflow_quantum as tfq\n",
        "import cirq \n",
        "import sympy\n",
        "class QDQN_alt(object):\n",
        "    def __init__(self, action_space, state_space, no_qubits=4) -> None:\n",
        "        super().__init__()\n",
        "        self.action_space = action_space\n",
        "        self.state_space = state_space\n",
        "        self.no_qubits = no_qubits\n",
        "        self.qubits = [cirq.GridQubit(0, i) for i in range(no_qubits)]\n",
        "        self.q_network = self.make_func_approx()\n",
        "        self.learning_rate = 0.01\n",
        "        self.opt = tf.keras.optimizers.Adam(lr=self.learning_rate)\n",
        "        self.buff = 10000\n",
        "        self.batch = 32   \n",
        "        self.states = np.zeros((self.buff, self.state_space))\n",
        "        self.actions = np.zeros((self.buff, 1))\n",
        "        self.rewards = np.zeros((self.buff, 1))\n",
        "        self.dones = np.zeros((self.buff, 1))\n",
        "        self.next_states = np.zeros((self.buff, self.state_space))\n",
        "        # Q Learning\n",
        "        self.gamma = 0.95\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_decay = 0.9\n",
        "        self.epsilon_min = 0.01\n",
        "        self.counter = 0\n",
        "        self.date = datetime.date.today()\n",
        "        self.model_name = \"QDQN-{date}_qbits{q}_ADAM_lr{lr}_bs{bs}_g{g}_eps{ep}_epsmin{epmin}_epsd{epd}\".format(\n",
        "            date=self.date,\n",
        "            q=self.no_qubits,g=self.gamma, bs=self.batch,\n",
        "            lr=self.learning_rate,\n",
        "            ep=self.epsilon,\n",
        "            epmin=self.epsilon_min,\n",
        "            epd=self.epsilon_decay)\n",
        "        self.msbe =None\n",
        "    def make_func_approx(self):\n",
        "        readout_operators = [cirq.Z(self.qubits[i]) for i in range(2,4)]\n",
        "        inputs = tf.keras.Input(shape=(), dtype=tf.dtypes.string)\n",
        "        diff = tfq.differentiators.ParameterShift()\n",
        "        init = tf.keras.initializers.Zeros\n",
        "        pqc = tfq.layers.PQC(self.make_circuit(self.qubits), readout_operators, differentiator=diff, initializer=init)(inputs)\n",
        "        model = tf.keras.Model(inputs=inputs, outputs=pqc)\n",
        "        return model\n",
        "\n",
        "    def convert_data(self, classical_data, flag=True):\n",
        "        ops = cirq.Circuit()\n",
        "        max_scale = max(classical_data)\n",
        "        min_scale = min(classical_data)\n",
        "        for i, ang in enumerate(classical_data):\n",
        "            ang = 2*np.pi*(ang-min_scale)/(max_scale-min_scale)\n",
        "            ops.append(cirq.rx(np.pi * ang).on(self.qubits[i]))\n",
        "            ops.append(cirq.rz(np.pi * ang).on(self.qubits[i]))\n",
        "        if flag:\n",
        "            return tfq.convert_to_tensor([ops])\n",
        "        else:\n",
        "            return ops\n",
        "\n",
        "    def one_qubit_unitary(self, bit, symbols):\n",
        "        return cirq.Circuit(\n",
        "            cirq.X(bit)**symbols[0],\n",
        "            cirq.Y(bit)**symbols[1],\n",
        "            cirq.Z(bit)**symbols[2])\n",
        "\n",
        "    def two_qubit_pool(self, source_qubit, sink_qubit, symbols):\n",
        "        pool_circuit = cirq.Circuit()\n",
        "        sink_basis_selector = self.one_qubit_unitary(sink_qubit, symbols[0:3])\n",
        "        source_basis_selector = self.one_qubit_unitary(source_qubit, symbols[3:6])\n",
        "        pool_circuit.append(sink_basis_selector)\n",
        "        pool_circuit.append(source_basis_selector)\n",
        "        pool_circuit.append(cirq.CNOT(control=source_qubit, target=sink_qubit))\n",
        "        pool_circuit.append(sink_basis_selector**-1)\n",
        "        return pool_circuit\n",
        "\n",
        "    def make_circuit(self, qubits):\n",
        "        m = cirq.Circuit()\n",
        "        no_vars = self.no_qubits*3*3 + 2*6\n",
        "        \n",
        "        no_vars_str = \"q0:\"+str(no_vars)\n",
        "        symbols = sympy.symbols(no_vars_str) # n qubits * 3 weights per bit * 3 layers + 2 * 6 pooling = 36 + 12 = 48\n",
        "        m += self.layer(symbols[:3*self.no_qubits], qubits)\n",
        "        m += self.layer(symbols[3*self.no_qubits:2*3*self.no_qubits], qubits)\n",
        "        m += self.layer(symbols[2*3*self.no_qubits:3*3*self.no_qubits], qubits)\n",
        "        m += self.two_qubit_pool(self.qubits[0], self.qubits[2], symbols[3*3*self.no_qubits:3*3*self.no_qubits+6])\n",
        "        m += self.two_qubit_pool(self.qubits[1], self.qubits[3], symbols[3*3*self.no_qubits+6:])\n",
        "        return m\n",
        "    \n",
        "    def layer(self, weights, qubits):\n",
        "        l = cirq.Circuit()\n",
        "\n",
        "        for i in range(len(qubits) - 1):\n",
        "            l.append(cirq.CNOT(qubits[i], qubits[i+1]))\n",
        "        l.append([cirq.Moment([cirq.rx(weights[j]).on(qubits[j]) for j in range(self.no_qubits)])])\n",
        "        l.append([cirq.Moment([cirq.ry(weights[j + self.no_qubits]).on(qubits[j]) for j in range(self.no_qubits)])])\n",
        "        l.append([cirq.Moment([cirq.rz(weights[j + 2*self.no_qubits]).on(qubits[j]) for j in range(self.no_qubits)])])\n",
        "        return l\n",
        "    \n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        i = self.counter % self.buff\n",
        "        self.states[i] = state\n",
        "        self.actions[i] = action\n",
        "        self.rewards[i] = reward\n",
        "        self.next_states[i] = next_state\n",
        "        self.dones[i] = int(done)\n",
        "        self.counter += 1\n",
        "\n",
        "    def get_action(self, obs):\n",
        "        if random.random() < self.epsilon: \n",
        "            return np.random.choice(self.action_space)\n",
        "        else:\n",
        "            return np.argmax(self.q_network.predict(self.convert_data(obs)))\n",
        "    def train(self):\n",
        "        batch_indices = np.random.choice(min(self.counter, self.buff), self.batch)\n",
        "        state_batch = tfq.convert_to_tensor([self.convert_data(i, False) for i in self.states[batch_indices]])\n",
        "        action_batch = tf.convert_to_tensor(self.actions[batch_indices])\n",
        "        action_batch = [[i, action_batch[i][0]] for i in range(len(action_batch))]\n",
        "        reward_batch = tf.convert_to_tensor(self.rewards[batch_indices])\n",
        "        dones_batch = tf.convert_to_tensor(self.dones[batch_indices])\n",
        "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
        "        action_batch = tf.cast(action_batch, dtype=tf.int32)\n",
        "        dones_batch = tf.cast(dones_batch, dtype=tf.float32)\n",
        "        next_state_batch = tfq.convert_to_tensor([self.convert_data(i, False) for i in self.next_states[batch_indices]])\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            next_q = self.q_network(next_state_batch)\n",
        "            y = reward_batch + (1 - dones_batch) * self.gamma * next_q\n",
        "            q_guess = self.q_network(state_batch, training=True)\n",
        "            pred = tf.gather_nd(q_guess, action_batch)\n",
        "            pred = tf.reshape(pred, [self.batch, 1])\n",
        "            msbe = tf.math.reduce_mean(tf.math.square(y - pred))\n",
        "            self.msbe=msbe\n",
        "        grads = tape.gradient(msbe, self.q_network.trainable_variables)\n",
        "        self.opt.apply_gradients(zip(grads, self.q_network.trainable_variables))\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "ITERATIONS = 750\n",
        "batch_size = 32\n",
        "windows = 50\n",
        "learn_delay = 500\n",
        "qubits = [4,8,12]\n",
        "\n",
        "for q in qubits:\n",
        "  losses = []\n",
        "  cur_loss = 1\n",
        "  env = gym.make(\"Blackjack-v0\")\n",
        "  env.seed(100)\n",
        "  agent = QDQN_alt(env.action_space.n, 3, q)\n",
        "  master_path = make_path(\"/content/drive/MyDrive/quantum_research/black_jack/quantum_models/\", \"200+\"+agent.model_name)\n",
        "  rewards = []\n",
        "  losses = []\n",
        "  cur_loss = 1\n",
        "  avg_reward = deque(maxlen=ITERATIONS)\n",
        "  best_avg_reward = -math.inf\n",
        "  rs = deque(maxlen=windows)\n",
        "  epi_times = []\n",
        "  start_time = time.process_time()\n",
        "\n",
        "  for i in range(ITERATIONS):\n",
        "      s1 = env.reset()\n",
        "      total_reward = 0\n",
        "      episode_losses=[]\n",
        "      done = False\n",
        "      episode_start = time.process_time()\n",
        "      while not done:\n",
        "          action = agent.get_action(s1)\n",
        "          s2, reward, done, info = env.step(action)\n",
        "          total_reward += reward\n",
        "          agent.remember(s1, action, reward, s2, done)\n",
        "          if agent.counter > learn_delay and done:\n",
        "              agent.train()\n",
        "              episode_losses.append(agent.msbe)\n",
        "          if done:\n",
        "              rewards.append(total_reward)\n",
        "              rs.append(total_reward)\n",
        "          s1 = s2\n",
        "      avg = np.mean(rs)\n",
        "      avg_reward.append(avg)\n",
        "      if avg > best_avg_reward:\n",
        "          best_avg_reward = avg\n",
        "      if len(episode_losses)>0:\n",
        "          EPISODE_LOSSES= np.asarray(episode_losses)\n",
        "          AVERAGE_EPISODE_LOSS = np.mean(EPISODE_LOSSES)\n",
        "          losses.append(AVERAGE_EPISODE_LOSS)\n",
        "          cur_loss = AVERAGE_EPISODE_LOSS\n",
        "      else:\n",
        "          losses.append(cur_loss)\n",
        "      epi_end = time.process_time() -episode_start\n",
        "      epi_times.append(epi_end)\n",
        "      print(\"\\rEpisode {}/{} || Best average reward {}, Current Iteration Reward {}\".format(i, ITERATIONS, best_avg_reward, total_reward))\n",
        "  reward_file = \"{h}/rewards\".format(h = master_path)\n",
        "  average_file = \"{h}/averages\".format(h=master_path)\n",
        "  times_file = \"{h}/times\".format(h=master_path)\n",
        "  loss_file = \"{h}/loss\".format(h=master_path)\n",
        "  np.save(reward_file , np.asarray(rewards))\n",
        "  np.save(average_file , np.asarray(avg_reward))\n",
        "  np.save(times_file , np.asarray(epi_times))\n",
        "  np.save(loss_file , np.asarray(losses))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking if /content/drive/MyDrive/quantum_research/black_jack/quantum_models/200+QDQN-2021-04-26_qbits4_ADAM_lr0.01_bs32_g0.95_eps1.0_epsmin0.01_epsd0.9 exists...\n",
            "finished!\n",
            "/content/drive/MyDrive/quantum_research/black_jack/quantum_models/200+QDQN-2021-04-26_qbits4_ADAM_lr0.01_bs32_g0.95_eps1.0_epsmin0.01_epsd0.9\n",
            "\rEpisode 0/750 || Best average reward -1.0, Current Iteration Reward -1.0\n",
            "\rEpisode 1/750 || Best average reward -1.0, Current Iteration Reward -1.0\n",
            "\rEpisode 2/750 || Best average reward -0.6666666666666666, Current Iteration Reward 0.0\n",
            "\rEpisode 3/750 || Best average reward -0.25, Current Iteration Reward 1.0\n",
            "\rEpisode 4/750 || Best average reward -0.25, Current Iteration Reward -1.0\n",
            "\rEpisode 5/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 6/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 7/750 || Best average reward -0.16666666666666666, Current Iteration Reward 0.0\n",
            "\rEpisode 8/750 || Best average reward -0.16666666666666666, Current Iteration Reward 0.0\n",
            "\rEpisode 9/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 10/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 11/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 12/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 13/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 14/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 15/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 16/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 17/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 18/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 19/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 20/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 21/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 22/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 23/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 24/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 25/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 26/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 27/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 28/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 29/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 30/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 31/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 32/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 33/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 34/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 35/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 36/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 37/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 38/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 39/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 40/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 41/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 42/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 43/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 44/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 45/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 46/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 47/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 48/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 49/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 50/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 51/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 52/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 53/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 54/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 55/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 56/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 57/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 58/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 59/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 60/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 61/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 62/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 63/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 64/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 65/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 66/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 67/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 68/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 69/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 70/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 71/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 72/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 73/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 74/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 75/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 76/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 77/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 78/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 79/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 80/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 81/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 82/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 83/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 84/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 85/750 || Best average reward -0.16666666666666666, Current Iteration Reward 0.0\n",
            "\rEpisode 86/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 87/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 88/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 89/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 90/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 91/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 92/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 93/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 94/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 95/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 96/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 97/750 || Best average reward -0.16666666666666666, Current Iteration Reward 0.0\n",
            "\rEpisode 98/750 || Best average reward -0.16666666666666666, Current Iteration Reward 0.0\n",
            "\rEpisode 99/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 100/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 101/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 102/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 103/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 104/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 105/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 106/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 107/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 108/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 109/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 110/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 111/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 112/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 113/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 114/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 115/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 116/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 117/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 118/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 119/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 120/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 121/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 122/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 123/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 124/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 125/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 126/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 127/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 128/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 129/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 130/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 131/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 132/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 133/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 134/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 135/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 136/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 137/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 138/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 139/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 140/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 141/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 142/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 143/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 144/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 145/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 146/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 147/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 148/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 149/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 150/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 151/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 152/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 153/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 154/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 155/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 156/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 157/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 158/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 159/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 160/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 161/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 162/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 163/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 164/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 165/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 166/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 167/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 168/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 169/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 170/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 171/750 || Best average reward -0.16666666666666666, Current Iteration Reward 0.0\n",
            "\rEpisode 172/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 173/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 174/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 175/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 176/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 177/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 178/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 179/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 180/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 181/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 182/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 183/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 184/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 185/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 186/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 187/750 || Best average reward -0.16666666666666666, Current Iteration Reward 0.0\n",
            "\rEpisode 188/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 189/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 190/750 || Best average reward -0.16666666666666666, Current Iteration Reward 0.0\n",
            "\rEpisode 191/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 192/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 193/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 194/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 195/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 196/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 197/750 || Best average reward -0.16666666666666666, Current Iteration Reward 0.0\n",
            "\rEpisode 198/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 199/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 200/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 201/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 202/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 203/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 204/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 205/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 206/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 207/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 208/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 209/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 210/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 211/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 212/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 213/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 214/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 215/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 216/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 217/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 218/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 219/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 220/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 221/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 222/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 223/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 224/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 225/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 226/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 227/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 228/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 229/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 230/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 231/750 || Best average reward -0.16666666666666666, Current Iteration Reward 0.0\n",
            "\rEpisode 232/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 233/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 234/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 235/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 236/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 237/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 238/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 239/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 240/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 241/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 242/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 243/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 244/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 245/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 246/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 247/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 248/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 249/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 250/750 || Best average reward -0.16666666666666666, Current Iteration Reward 0.0\n",
            "\rEpisode 251/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 252/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 253/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 254/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 255/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 256/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 257/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 258/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 259/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 260/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 261/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 262/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 263/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 264/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 265/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 266/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 267/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 268/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 269/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 270/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 271/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 272/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 273/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 274/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 275/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 276/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 277/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 278/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 279/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 280/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 281/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 282/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 283/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 284/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 285/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 286/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 287/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 288/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 289/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 290/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 291/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 292/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 293/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 294/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 295/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 296/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 297/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 298/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 299/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 300/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 301/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 302/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 303/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 304/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 305/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 306/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 307/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 308/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 309/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 310/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 311/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 312/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 313/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 314/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 315/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 316/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 317/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 318/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 319/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 320/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 321/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 322/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 323/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 324/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 325/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 326/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 327/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 328/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 329/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 330/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 331/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 332/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 333/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 334/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 335/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 336/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 337/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "\rEpisode 338/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 339/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 340/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 341/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 342/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 343/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 344/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 345/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "\rEpisode 346/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 347/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 348/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 349/750 || Best average reward -0.16666666666666666, Current Iteration Reward 0.0\n",
            "Episode 350/750 || Best average reward -0.16666666666666666, Current Iteration Reward 0.0\n",
            "Episode 351/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 352/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 353/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 354/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 355/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 356/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 357/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 358/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 359/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 360/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 361/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 362/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 363/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 364/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 365/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 366/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 367/750 || Best average reward -0.16666666666666666, Current Iteration Reward 0.0\n",
            "Episode 368/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 369/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 370/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 371/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 372/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 373/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 374/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 375/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 376/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 377/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 378/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 379/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 380/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 381/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 382/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 383/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 384/750 || Best average reward -0.16666666666666666, Current Iteration Reward 0.0\n",
            "Episode 385/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 386/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 387/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 388/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 389/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 390/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 391/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 392/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 393/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 394/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 395/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 396/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 397/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 398/750 || Best average reward -0.16666666666666666, Current Iteration Reward 0.0\n",
            "Episode 399/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 400/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 401/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 402/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 403/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 404/750 || Best average reward -0.16666666666666666, Current Iteration Reward 0.0\n",
            "Episode 405/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 406/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 407/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 408/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 409/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 410/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 411/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 412/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 413/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 414/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 415/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 416/750 || Best average reward -0.16666666666666666, Current Iteration Reward 1.0\n",
            "Episode 417/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 418/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 419/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 420/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 421/750 || Best average reward -0.16666666666666666, Current Iteration Reward -1.0\n",
            "Episode 422/750 || Best average reward -0.16666666666666666, Current Iteration Reward 0.0\n",
            "Episode 423/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 424/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 425/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 426/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 427/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 428/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 429/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 430/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 431/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 432/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 433/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 434/750 || Best average reward -0.16, Current Iteration Reward 0.0\n",
            "Episode 435/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 436/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 437/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 438/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 439/750 || Best average reward -0.16, Current Iteration Reward 0.0\n",
            "Episode 440/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 441/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 442/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 443/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 444/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 445/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 446/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 447/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 448/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 449/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 450/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 451/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 452/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 453/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 454/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 455/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 456/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 457/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 458/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 459/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 460/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 461/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 462/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 463/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 464/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 465/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 466/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 467/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 468/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 469/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 470/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 471/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 472/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 473/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 474/750 || Best average reward -0.16, Current Iteration Reward -1.0\n",
            "Episode 475/750 || Best average reward -0.16, Current Iteration Reward 1.0\n",
            "Episode 476/750 || Best average reward -0.12, Current Iteration Reward 1.0\n",
            "Episode 477/750 || Best average reward -0.08, Current Iteration Reward 1.0\n",
            "Episode 478/750 || Best average reward -0.08, Current Iteration Reward -1.0\n",
            "Episode 479/750 || Best average reward -0.08, Current Iteration Reward -1.0\n",
            "Episode 480/750 || Best average reward -0.06, Current Iteration Reward 0.0\n",
            "Episode 481/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 482/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 483/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 484/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 485/750 || Best average reward -0.06, Current Iteration Reward 0.0\n",
            "Episode 486/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 487/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 488/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 489/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 490/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 491/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 492/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 493/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 494/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 495/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 496/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 497/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 498/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 499/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 500/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 501/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 502/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 503/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 504/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 505/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 506/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 507/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 508/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 509/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 510/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 511/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 512/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 513/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 514/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 515/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 516/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 517/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 518/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 519/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 520/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 521/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 522/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 523/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 524/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 525/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 526/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 527/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 528/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 529/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 530/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 531/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 532/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 533/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 534/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 535/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 536/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 537/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 538/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 539/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 540/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 541/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 542/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 543/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 544/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 545/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 546/750 || Best average reward -0.06, Current Iteration Reward 0.0\n",
            "Episode 547/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 548/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 549/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 550/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 551/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 552/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 553/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 554/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 555/750 || Best average reward -0.06, Current Iteration Reward -1.0\n",
            "Episode 556/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 557/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 558/750 || Best average reward -0.06, Current Iteration Reward 1.0\n",
            "Episode 559/750 || Best average reward -0.02, Current Iteration Reward 1.0\n",
            "Episode 560/750 || Best average reward -0.02, Current Iteration Reward -1.0\n",
            "Episode 561/750 || Best average reward -0.02, Current Iteration Reward -1.0\n",
            "Episode 562/750 || Best average reward -0.02, Current Iteration Reward 1.0\n",
            "Episode 563/750 || Best average reward -0.02, Current Iteration Reward -1.0\n",
            "Episode 564/750 || Best average reward -0.02, Current Iteration Reward -1.0\n",
            "Episode 565/750 || Best average reward -0.02, Current Iteration Reward 1.0\n",
            "Episode 566/750 || Best average reward -0.02, Current Iteration Reward -1.0\n",
            "Episode 567/750 || Best average reward -0.02, Current Iteration Reward 1.0\n",
            "Episode 568/750 || Best average reward -0.02, Current Iteration Reward -1.0\n",
            "Episode 569/750 || Best average reward -0.02, Current Iteration Reward 1.0\n",
            "Episode 570/750 || Best average reward -0.02, Current Iteration Reward -1.0\n",
            "Episode 571/750 || Best average reward -0.02, Current Iteration Reward -1.0\n",
            "Episode 572/750 || Best average reward -0.02, Current Iteration Reward 1.0\n",
            "Episode 573/750 || Best average reward 0.02, Current Iteration Reward 1.0\n",
            "Episode 574/750 || Best average reward 0.02, Current Iteration Reward -1.0\n",
            "Episode 575/750 || Best average reward 0.02, Current Iteration Reward 1.0\n",
            "Episode 576/750 || Best average reward 0.02, Current Iteration Reward -1.0\n",
            "Episode 577/750 || Best average reward 0.02, Current Iteration Reward -1.0\n",
            "Episode 578/750 || Best average reward 0.02, Current Iteration Reward 1.0\n",
            "Episode 579/750 || Best average reward 0.02, Current Iteration Reward 1.0\n",
            "Episode 580/750 || Best average reward 0.02, Current Iteration Reward 1.0\n",
            "Episode 581/750 || Best average reward 0.02, Current Iteration Reward -1.0\n",
            "Episode 582/750 || Best average reward 0.02, Current Iteration Reward -1.0\n",
            "Episode 583/750 || Best average reward 0.02, Current Iteration Reward 1.0\n",
            "Episode 584/750 || Best average reward 0.02, Current Iteration Reward -1.0\n",
            "Episode 585/750 || Best average reward 0.02, Current Iteration Reward -1.0\n",
            "Episode 586/750 || Best average reward 0.02, Current Iteration Reward -1.0\n",
            "Episode 587/750 || Best average reward 0.02, Current Iteration Reward 1.0\n",
            "Episode 588/750 || Best average reward 0.02, Current Iteration Reward -1.0\n",
            "Episode 589/750 || Best average reward 0.02, Current Iteration Reward 1.0\n",
            "Episode 590/750 || Best average reward 0.02, Current Iteration Reward 1.0\n",
            "Episode 591/750 || Best average reward 0.02, Current Iteration Reward 1.0\n",
            "Episode 592/750 || Best average reward 0.02, Current Iteration Reward 1.0\n",
            "Episode 593/750 || Best average reward 0.02, Current Iteration Reward -1.0\n",
            "Episode 594/750 || Best average reward 0.02, Current Iteration Reward -1.0\n",
            "Episode 595/750 || Best average reward 0.06, Current Iteration Reward 1.0\n",
            "Episode 596/750 || Best average reward 0.06, Current Iteration Reward -1.0\n",
            "Episode 597/750 || Best average reward 0.06, Current Iteration Reward 1.0\n",
            "Episode 598/750 || Best average reward 0.06, Current Iteration Reward 0.0\n",
            "Episode 599/750 || Best average reward 0.06, Current Iteration Reward -1.0\n",
            "Episode 600/750 || Best average reward 0.06, Current Iteration Reward 1.0\n",
            "Episode 601/750 || Best average reward 0.06, Current Iteration Reward 1.0\n",
            "Episode 602/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 603/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 604/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 605/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 606/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 607/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 608/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 609/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 610/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 611/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 612/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 613/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 614/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 615/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 616/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 617/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 618/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 619/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 620/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 621/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 622/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 623/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 624/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 625/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 626/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 627/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 628/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 629/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 630/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 631/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 632/750 || Best average reward 0.1, Current Iteration Reward 0.0\n",
            "Episode 633/750 || Best average reward 0.1, Current Iteration Reward 0.0\n",
            "Episode 634/750 || Best average reward 0.1, Current Iteration Reward 0.0\n",
            "Episode 635/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 636/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 637/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 638/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 639/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 640/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 641/750 || Best average reward 0.1, Current Iteration Reward 0.0\n",
            "Episode 642/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 643/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 644/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 645/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 646/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 647/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 648/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 649/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 650/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 651/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 652/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 653/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 654/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 655/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 656/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 657/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 658/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 659/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 660/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 661/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 662/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 663/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 664/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 665/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 666/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 667/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 668/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 669/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 670/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 671/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 672/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 673/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 674/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 675/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 676/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 677/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 678/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 679/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 680/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 681/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 682/750 || Best average reward 0.1, Current Iteration Reward 0.0\n",
            "Episode 683/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 684/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 685/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 686/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 687/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 688/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 689/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 690/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 691/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 692/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 693/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 694/750 || Best average reward 0.1, Current Iteration Reward 0.0\n",
            "Episode 695/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 696/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 697/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 698/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 699/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 700/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 701/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 702/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 703/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 704/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 705/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 706/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 707/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 708/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 709/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 710/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 711/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 712/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 713/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 714/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 715/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 716/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 717/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 718/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 719/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 720/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 721/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 722/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 723/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 724/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 725/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 726/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 727/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 728/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 729/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 730/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 731/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 732/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 733/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 734/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 735/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 736/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 737/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 738/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 739/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 740/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 741/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 742/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 743/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 744/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 745/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 746/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 747/750 || Best average reward 0.1, Current Iteration Reward 1.0\n",
            "Episode 748/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Episode 749/750 || Best average reward 0.1, Current Iteration Reward -1.0\n",
            "Checking if /content/drive/MyDrive/quantum_research/black_jack/quantum_models/200+QDQN-2021-04-26_qbits8_ADAM_lr0.01_bs32_g0.95_eps1.0_epsmin0.01_epsd0.9 exists...\n",
            "finished!\n",
            "/content/drive/MyDrive/quantum_research/black_jack/quantum_models/200+QDQN-2021-04-26_qbits8_ADAM_lr0.01_bs32_g0.95_eps1.0_epsmin0.01_epsd0.9\n",
            "Episode 0/750 || Best average reward -1.0, Current Iteration Reward -1.0\n",
            "Episode 1/750 || Best average reward 0.0, Current Iteration Reward 1.0\n",
            "Episode 2/750 || Best average reward 0.3333333333333333, Current Iteration Reward 1.0\n",
            "Episode 3/750 || Best average reward 0.5, Current Iteration Reward 1.0\n",
            "Episode 4/750 || Best average reward 0.6, Current Iteration Reward 1.0\n",
            "Episode 5/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 6/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 7/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 8/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 9/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 10/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 11/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 12/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 13/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 14/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 15/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 16/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 17/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 18/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 19/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 20/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 21/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 22/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 23/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 24/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 25/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 26/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 27/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 28/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 29/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 30/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 31/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 32/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 33/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 34/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 35/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 36/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 37/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 38/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 39/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 40/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 41/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 42/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 43/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 44/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 45/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 46/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 47/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 48/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 49/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 50/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 51/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 52/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 53/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 54/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 55/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 56/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 57/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 58/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 59/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 60/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 61/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 62/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 63/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 64/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 65/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 66/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 67/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 68/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 69/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 70/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 71/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 72/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 73/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 74/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 75/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 76/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 77/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 78/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 79/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 80/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 81/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 82/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 83/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 84/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 85/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 86/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 87/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 88/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 89/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 90/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 91/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 92/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 93/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 94/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 95/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 96/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 97/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 98/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 99/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 100/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 101/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 102/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 103/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 104/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 105/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 106/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 107/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 108/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 109/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 110/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 111/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 112/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 113/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 114/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 115/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 116/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 117/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 118/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 119/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 120/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 121/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 122/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 123/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 124/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 125/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 126/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 127/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 128/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 129/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 130/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 131/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 132/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 133/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 134/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 135/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 136/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 137/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 138/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 139/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 140/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 141/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 142/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 143/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 144/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 145/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 146/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 147/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 148/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 149/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 150/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 151/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 152/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 153/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 154/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 155/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 156/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 157/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 158/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 159/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 160/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 161/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 162/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 163/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 164/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 165/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 166/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 167/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 168/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 169/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 170/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 171/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 172/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 173/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 174/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 175/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 176/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 177/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 178/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 179/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 180/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 181/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 182/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 183/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 184/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 185/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 186/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 187/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 188/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 189/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 190/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 191/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 192/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 193/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 194/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 195/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 196/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 197/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 198/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 199/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 200/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 201/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 202/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 203/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 204/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 205/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 206/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 207/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 208/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 209/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 210/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 211/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 212/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 213/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 214/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 215/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 216/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 217/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 218/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 219/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 220/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 221/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 222/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 223/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 224/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 225/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 226/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 227/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 228/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 229/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 230/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 231/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 232/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 233/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 234/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 235/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 236/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 237/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 238/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 239/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 240/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 241/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 242/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 243/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 244/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 245/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 246/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 247/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 248/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 249/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 250/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 251/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 252/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 253/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 254/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 255/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 256/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 257/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 258/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 259/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 260/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 261/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 262/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 263/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 264/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 265/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 266/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 267/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 268/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 269/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 270/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 271/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 272/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 273/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 274/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 275/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 276/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 277/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 278/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 279/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 280/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 281/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 282/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 283/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 284/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 285/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 286/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 287/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 288/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 289/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 290/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 291/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 292/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 293/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 294/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 295/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 296/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 297/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 298/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 299/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 300/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 301/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 302/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 303/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 304/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 305/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 306/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 307/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 308/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 309/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 310/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 311/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 312/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 313/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 314/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 315/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 316/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 317/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 318/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 319/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 320/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 321/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 322/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 323/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 324/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 325/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 326/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 327/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 328/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 329/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 330/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 331/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 332/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 333/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 334/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 335/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 336/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 337/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 338/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 339/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 340/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 341/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 342/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 343/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 344/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 345/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 346/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 347/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 348/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 349/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 350/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 351/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 352/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 353/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 354/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 355/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 356/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 357/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 358/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 359/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 360/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 361/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 362/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 363/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 364/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 365/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 366/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 367/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 368/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 369/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 370/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 371/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 372/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 373/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 374/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 375/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 376/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 377/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 378/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 379/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 380/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 381/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 382/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 383/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 384/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 385/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 386/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 387/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 388/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 389/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 390/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 391/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 392/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 393/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 394/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 395/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 396/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 397/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 398/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 399/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 400/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 401/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 402/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 403/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 404/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 405/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 406/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 407/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 408/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 409/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 410/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 411/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 412/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 413/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 414/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 415/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 416/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 417/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 418/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 419/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 420/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 421/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 422/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 423/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 424/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 425/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 426/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 427/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 428/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 429/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 430/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 431/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 432/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 433/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 434/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 435/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 436/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 437/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 438/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 439/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 440/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 441/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 442/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 443/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 444/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 445/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 446/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 447/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 448/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 449/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 450/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 451/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 452/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 453/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 454/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 455/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 456/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 457/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 458/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 459/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 460/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 461/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 462/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 463/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 464/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 465/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 466/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 467/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 468/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 469/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 470/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 471/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 472/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 473/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 474/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 475/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 476/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 477/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 478/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 479/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 480/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 481/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 482/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 483/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 484/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 485/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 486/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 487/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 488/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 489/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 490/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 491/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 492/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 493/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 494/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 495/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 496/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 497/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 498/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 499/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 500/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 501/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 502/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 503/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 504/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 505/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 506/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 507/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 508/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 509/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 510/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 511/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 512/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 513/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 514/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 515/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 516/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 517/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 518/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 519/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 520/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 521/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 522/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 523/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 524/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 525/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 526/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 527/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 528/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 529/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 530/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 531/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 532/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 533/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 534/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 535/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 536/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 537/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 538/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 539/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 540/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 541/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 542/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 543/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 544/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 545/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 546/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 547/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 548/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 549/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 550/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 551/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 552/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 553/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 554/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 555/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 556/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 557/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 558/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 559/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 560/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 561/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 562/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 563/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 564/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 565/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 566/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 567/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 568/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 569/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 570/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 571/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 572/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 573/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 574/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 575/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 576/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 577/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 578/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 579/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 580/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 581/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 582/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 583/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 584/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 585/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 586/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 587/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 588/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 589/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 590/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 591/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 592/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 593/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 594/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 595/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 596/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 597/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 598/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 599/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 600/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 601/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 602/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 603/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 604/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 605/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 606/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 607/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 608/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 609/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 610/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 611/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 612/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 613/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 614/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 615/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 616/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 617/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 618/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 619/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 620/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 621/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 622/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 623/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 624/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 625/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 626/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 627/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 628/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 629/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 630/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 631/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 632/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 633/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 634/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 635/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 636/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 637/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 638/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 639/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 640/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 641/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 642/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 643/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 644/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 645/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 646/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 647/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 648/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 649/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 650/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 651/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 652/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 653/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 654/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 655/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 656/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 657/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 658/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 659/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 660/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 661/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 662/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 663/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 664/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 665/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 666/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 667/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 668/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 669/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 670/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 671/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 672/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 673/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 674/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 675/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 676/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 677/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 678/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 679/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 680/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 681/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 682/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 683/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 684/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 685/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 686/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 687/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 688/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 689/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 690/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 691/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 692/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 693/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 694/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 695/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 696/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 697/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 698/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 699/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 700/750 || Best average reward 0.6666666666666666, Current Iteration Reward 0.0\n",
            "Episode 701/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 702/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 703/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 704/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 705/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 706/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 707/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 708/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 709/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 710/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 711/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 712/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 713/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 714/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 715/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 716/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 717/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 718/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 719/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 720/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 721/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 722/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 723/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 724/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 725/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 726/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 727/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 728/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 729/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 730/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 731/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 732/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 733/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 734/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 735/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 736/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 737/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 738/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 739/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 740/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 741/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 742/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 743/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 744/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 745/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 746/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Episode 747/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 748/750 || Best average reward 0.6666666666666666, Current Iteration Reward -1.0\n",
            "Episode 749/750 || Best average reward 0.6666666666666666, Current Iteration Reward 1.0\n",
            "Checking if /content/drive/MyDrive/quantum_research/black_jack/quantum_models/200+QDQN-2021-04-26_qbits12_ADAM_lr0.01_bs32_g0.95_eps1.0_epsmin0.01_epsd0.9 exists...\n",
            "finished!\n",
            "/content/drive/MyDrive/quantum_research/black_jack/quantum_models/200+QDQN-2021-04-26_qbits12_ADAM_lr0.01_bs32_g0.95_eps1.0_epsmin0.01_epsd0.9\n",
            "Episode 0/750 || Best average reward -1.0, Current Iteration Reward -1.0\n",
            "Episode 1/750 || Best average reward -1.0, Current Iteration Reward -1.0\n",
            "Episode 2/750 || Best average reward -0.3333333333333333, Current Iteration Reward 1.0\n",
            "Episode 3/750 || Best average reward 0.0, Current Iteration Reward 1.0\n",
            "Episode 4/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 5/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 6/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 7/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 8/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 9/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 10/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 11/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 12/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 13/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 14/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 15/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 16/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 17/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 18/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 19/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 20/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 21/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 22/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 23/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 24/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 25/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 26/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 27/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 28/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 29/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 30/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 31/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 32/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 33/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 34/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 35/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 36/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 37/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 38/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 39/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 40/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 41/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 42/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 43/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 44/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 45/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 46/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 47/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 48/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 49/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 50/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 51/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 52/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 53/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 54/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 55/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 56/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 57/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 58/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 59/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 60/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 61/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 62/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 63/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 64/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 65/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 66/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 67/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 68/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 69/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 70/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 71/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 72/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 73/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 74/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 75/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 76/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 77/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 78/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 79/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 80/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 81/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 82/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 83/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 84/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 85/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 86/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 87/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 88/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 89/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 90/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 91/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 92/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 93/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 94/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 95/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 96/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 97/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 98/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 99/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 100/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 101/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 102/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 103/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 104/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 105/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 106/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 107/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 108/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 109/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 110/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 111/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 112/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 113/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 114/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 115/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 116/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 117/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 118/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 119/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 120/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 121/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 122/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 123/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 124/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 125/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 126/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 127/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 128/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 129/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 130/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 131/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 132/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 133/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 134/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 135/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 136/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 137/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 138/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 139/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 140/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 141/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 142/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 143/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 144/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 145/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 146/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 147/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 148/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 149/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 150/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 151/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 152/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 153/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 154/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 155/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 156/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 157/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 158/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 159/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 160/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 161/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 162/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 163/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 164/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 165/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 166/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 167/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 168/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 169/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 170/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 171/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 172/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 173/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 174/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 175/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 176/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 177/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 178/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 179/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 180/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 181/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 182/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 183/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 184/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 185/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 186/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 187/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 188/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 189/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 190/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 191/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 192/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 193/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 194/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 195/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 196/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 197/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 198/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 199/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 200/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 201/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 202/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 203/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 204/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 205/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 206/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 207/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 208/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 209/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 210/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 211/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 212/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 213/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 214/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 215/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 216/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 217/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 218/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 219/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 220/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 221/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 222/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 223/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 224/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 225/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 226/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 227/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 228/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 229/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 230/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 231/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 232/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 233/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 234/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 235/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 236/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 237/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 238/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 239/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 240/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 241/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 242/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 243/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 244/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 245/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 246/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 247/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 248/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 249/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 250/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 251/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 252/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 253/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 254/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 255/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 256/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 257/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 258/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 259/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 260/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 261/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 262/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 263/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 264/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 265/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 266/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 267/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 268/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 269/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 270/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 271/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 272/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 273/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 274/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 275/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 276/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 277/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 278/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 279/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 280/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 281/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 282/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 283/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 284/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 285/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 286/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 287/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 288/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 289/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 290/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 291/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 292/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 293/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 294/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 295/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 296/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 297/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 298/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 299/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 300/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 301/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 302/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 303/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 304/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 305/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 306/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 307/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 308/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 309/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 310/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 311/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 312/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 313/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 314/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 315/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 316/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 317/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 318/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 319/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 320/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 321/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 322/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 323/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 324/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 325/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 326/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 327/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 328/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 329/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 330/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 331/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 332/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 333/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 334/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 335/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 336/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 337/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 338/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 339/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 340/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 341/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 342/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 343/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 344/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 345/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 346/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 347/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 348/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 349/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 350/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 351/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 352/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 353/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 354/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 355/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 356/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 357/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 358/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 359/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 360/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 361/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 362/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 363/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 364/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 365/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 366/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 367/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 368/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 369/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 370/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 371/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 372/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 373/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 374/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 375/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 376/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 377/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 378/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 379/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 380/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 381/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 382/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 383/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 384/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 385/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 386/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 387/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 388/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 389/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 390/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 391/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 392/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 393/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 394/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 395/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 396/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 397/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 398/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 399/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 400/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 401/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 402/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 403/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 404/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 405/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 406/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 407/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 408/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 409/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 410/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 411/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 412/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 413/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 414/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 415/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 416/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 417/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 418/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 419/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 420/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 421/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 422/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 423/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 424/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 425/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 426/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 427/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 428/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 429/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 430/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 431/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 432/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 433/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 434/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 435/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 436/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 437/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 438/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 439/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 440/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 441/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 442/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 443/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 444/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 445/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 446/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 447/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 448/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 449/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 450/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 451/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 452/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 453/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 454/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 455/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 456/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 457/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 458/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 459/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 460/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 461/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 462/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 463/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 464/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 465/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 466/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 467/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 468/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 469/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 470/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 471/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 472/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 473/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 474/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 475/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 476/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 477/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 478/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 479/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 480/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 481/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 482/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 483/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 484/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 485/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 486/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 487/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 488/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 489/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 490/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 491/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 492/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 493/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 494/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 495/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 496/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 497/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 498/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 499/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 500/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 501/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 502/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 503/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 504/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 505/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 506/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 507/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 508/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 509/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 510/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 511/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 512/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 513/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 514/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 515/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 516/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 517/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 518/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 519/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 520/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 521/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 522/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 523/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 524/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 525/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 526/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 527/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 528/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 529/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 530/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 531/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 532/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 533/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 534/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 535/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 536/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 537/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 538/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 539/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 540/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 541/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 542/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 543/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 544/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 545/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 546/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 547/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 548/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 549/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 550/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 551/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 552/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 553/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 554/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 555/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 556/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 557/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 558/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 559/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 560/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 561/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 562/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 563/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 564/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 565/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 566/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 567/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 568/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 569/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 570/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 571/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 572/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 573/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 574/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 575/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 576/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 577/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 578/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 579/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 580/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 581/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 582/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 583/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 584/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 585/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 586/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 587/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 588/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 589/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 590/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 591/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 592/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 593/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 594/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 595/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 596/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 597/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 598/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 599/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 600/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 601/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 602/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 603/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 604/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 605/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 606/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 607/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 608/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 609/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 610/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 611/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 612/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 613/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 614/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 615/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 616/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 617/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 618/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 619/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 620/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 621/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 622/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 623/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 624/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 625/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 626/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 627/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 628/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 629/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 630/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 631/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 632/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 633/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 634/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 635/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 636/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 637/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 638/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 639/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 640/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 641/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 642/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 643/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 644/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 645/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 646/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 647/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 648/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 649/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 650/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 651/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 652/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 653/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 654/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 655/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 656/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 657/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 658/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 659/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 660/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 661/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 662/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 663/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 664/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 665/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 666/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 667/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 668/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 669/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 670/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 671/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 672/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 673/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 674/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 675/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 676/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 677/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 678/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 679/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 680/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 681/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 682/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 683/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 684/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 685/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 686/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 687/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 688/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 689/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 690/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 691/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 692/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 693/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 694/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 695/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 696/750 || Best average reward 0.2, Current Iteration Reward 0.0\n",
            "Episode 697/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 698/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 699/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 700/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 701/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 702/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 703/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 704/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 705/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 706/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 707/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 708/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 709/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 710/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 711/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 712/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 713/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 714/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 715/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 716/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 717/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 718/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 719/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 720/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 721/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 722/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 723/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 724/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 725/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 726/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 727/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 728/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 729/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 730/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 731/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 732/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 733/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 734/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 735/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 736/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 737/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 738/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 739/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 740/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 741/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 742/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 743/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 744/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 745/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 746/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 747/750 || Best average reward 0.2, Current Iteration Reward -1.0\n",
            "Episode 748/750 || Best average reward 0.2, Current Iteration Reward 1.0\n",
            "Episode 749/750 || Best average reward 0.2, Current Iteration Reward 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzb1-f5PZdhS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}